{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from tabulate import tabulate\n",
    "import nltk\n",
    "from math import sqrt\n",
    "\n",
    "# Function to download financial data\n",
    "def download_data(ticker, start_date, end_date):\n",
    "    try:\n",
    "        df = yf.download(ticker, start=start_date, end=end_date)\n",
    "        df = df['Close'].rename(ticker)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading data for {ticker}: {e}\")\n",
    "        return pd.Series(name=ticker)\n",
    "\n",
    "# Setting start and end dates for data\n",
    "end_date = datetime.datetime.now().strftime('%Y-%m-%d')\n",
    "start_date = (datetime.datetime.now() - datetime.timedelta(days=20*365)).strftime('%Y-%m-%d')\n",
    "\n",
    "# List of tickers to download data for\n",
    "tickers = ['FRSH', 'NEM', 'XOM', 'INR=X']\n",
    "\n",
    "# Downloading data for each ticker and merging\n",
    "dataframes = [download_data(ticker, start_date, end_date) for ticker in tickers]\n",
    "merged_data = pd.concat(dataframes, axis=1).dropna()\n",
    "merged_data.columns = ['FRESHWORKS', 'GOLD', 'PETROL', 'CURRENCY']\n",
    "\n",
    "# Saving merged data to a CSV file\n",
    "merged_data.to_csv('merged_data.csv')\n",
    "\n",
    "# Checking for NaN values\n",
    "if merged_data.isna().any().any():\n",
    "    print(\"Warning: NaN values present in the merged data.\")\n",
    "else:\n",
    "    print(\"Data downloaded and merged successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading merged data from CSV\n",
    "data = pd.read_csv('merged_data.csv')\n",
    "\n",
    "# Converting 'Date' column to datetime format\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "# Setting 'Date' column as index\n",
    "data.set_index('Date', inplace=True)\n",
    "\n",
    "# Dropping rows with NaN values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Displaying data types of columns\n",
    "print(data.dtypes)\n",
    "\n",
    "# Displaying data\n",
    "print(data.head())\n",
    "\n",
    "# Splitting data into features (X) and target (y)\n",
    "X = data[['GOLD', 'PETROL', 'CURRENCY']]\n",
    "y = data['FRESHWORKS']\n",
    "\n",
    "# Splitting data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fitting Linear Regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculating evaluation metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Displaying actual and predicted values in a table\n",
    "results_table = pd.DataFrame({'Actual RELIANCE': y_test, 'Predicted RELIANCE': y_pred})\n",
    "print(\"Actual vs. Predicted Values:\")\n",
    "print(results_table)\n",
    "\n",
    "# Displaying evaluation metrics\n",
    "print(f'\\nMean Squared Error (MSE): {mse}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
    "print(f'Mean Absolute Error (MAE): {mae}')\n",
    "print(f'R-squared: {r2}')\n",
    "\n",
    "# Plotting scatter plots\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
    "axes[0].scatter(X_test['GOLD'], y_test, color='blue', label='Actual RELIANCE')\n",
    "axes[0].scatter(X_test['GOLD'], y_pred, color='red', label='Predicted RELIANCE')\n",
    "axes[0].set_xlabel('GOLD')\n",
    "axes[0].set_ylabel('FRESHWORKS')\n",
    "axes[0].set_title('GOLD vs. RELIANCE')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].scatter(X_test['PETROL'], y_test, color='blue', label='Actual RELIANCE')\n",
    "axes[1].scatter(X_test['PETROL'], y_pred, color='red', label='Predicted RELIANCE')\n",
    "axes[1].set_xlabel('PETROL')\n",
    "axes[1].set_ylabel('FRESHWORKS')\n",
    "axes[1].set_title('PETROL vs. RELIANCE')\n",
    "axes[1].legend()\n",
    "\n",
    "axes[2].scatter(X_test['CURRENCY'], y_test, color='blue', label='Actual RELIANCE')\n",
    "axes[2].scatter(X_test['CURRENCY'], y_pred, color='red', label='Predicted RELIANCE')\n",
    "axes[2].set_xlabel('CURRENCY')\n",
    "axes[2].set_ylabel('FRESHWORKS')\n",
    "axes[2].set_title('CURRENCY vs. RELIANCE')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate evaluation metrics\n",
    "def calculate_metrics(y_test, y_pred):\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    return mse, rmse, r2\n",
    "\n",
    "# Splitting data into features (X) and target (y)\n",
    "X = data[['GOLD', 'PETROL', 'CURRENCY']]\n",
    "y = data['FRESHWORKS']\n",
    "\n",
    "# Dictionary to store metrics for each feature\n",
    "metrics_dict_rf = {'Feature': [], 'MSE': [], 'RMSE': [], 'R-squared': []}\n",
    "\n",
    "# Loop through each feature\n",
    "for feature in X.columns:\n",
    "    current_feature = X[[feature]]\n",
    "\n",
    "    # Splitting data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(current_feature, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Fitting Random Forest model\n",
    "    model_rf = RandomForestRegressor(random_state=42)\n",
    "    model_rf.fit(X_train, y_train)\n",
    "\n",
    "    # Predicting on test set\n",
    "    y_pred_rf = model_rf.predict(X_test)\n",
    "\n",
    "    # Calculating evaluation metrics\n",
    "    mse_rf, rmse_rf, r2_rf = calculate_metrics(y_test, y_pred_rf)\n",
    "\n",
    "    # Storing metrics in dictionary\n",
    "    metrics_dict_rf['Feature'].append(feature)\n",
    "    metrics_dict_rf['MSE'].append(mse_rf)\n",
    "    metrics_dict_rf['RMSE'].append(rmse_rf)\n",
    "    metrics_dict_rf['R-squared'].append(r2_rf)\n",
    "\n",
    "# Creating DataFrame to display metrics\n",
    "results_df_rf = pd.DataFrame(metrics_dict_rf)\n",
    "print(results_df_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store metrics for each feature\n",
    "metrics_dict_knn = {'Feature': [], 'MSE': [], 'RMSE': [], 'R-squared': []}\n",
    "\n",
    "# Loop through each feature\n",
    "for feature in X.columns:\n",
    "    current_feature = X[[feature]]\n",
    "\n",
    "    # Splitting data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(current_feature, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Fitting KNN model\n",
    "    model_knn = KNeighborsRegressor(n_neighbors=5)\n",
    "    model_knn.fit(X_train, y_train)\n",
    "\n",
    "    # Predicting on test set\n",
    "    y_pred_knn = model_knn.predict(X_test)\n",
    "\n",
    "    # Calculating evaluation metrics\n",
    "    mse_knn, rmse_knn, r2_knn = calculate_metrics(y_test, y_pred_knn)\n",
    "\n",
    "    # Storing metrics in dictionary\n",
    "    metrics_dict_knn['Feature'].append(feature)\n",
    "    metrics_dict_knn['MSE'].append(mse_knn)\n",
    "    metrics_dict_knn['RMSE'].append(rmse_knn)\n",
    "    metrics_dict_knn['R-squared'].append(r2_knn)\n",
    "\n",
    "# Creating DataFrame to display metrics\n",
    "results_df_knn = pd.DataFrame(metrics_dict_knn)\n",
    "print(results_df_knn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate evaluation metrics\n",
    "def calculate_metrics(y_test, y_pred):\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    return mse, rmse, r2\n",
    "\n",
    "# Splitting data into features (X) and target (y)\n",
    "X = data[['GOLD', 'PETROL', 'CURRENCY']]\n",
    "y = data['FRESHWORKS']\n",
    "\n",
    "# Splitting data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scaling features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Defining the architecture of the ANN model\n",
    "model_ann = Sequential()\n",
    "model_ann.add(Dense(32, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model_ann.add(Dense(16, activation='relu'))\n",
    "model_ann.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compiling the model\n",
    "model_ann.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Training the model\n",
    "model_ann.fit(X_train_scaled, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "# Predicting on test set\n",
    "y_pred_ann = model_ann.predict(X_test_scaled).flatten()\n",
    "\n",
    "# Calculating evaluation metrics\n",
    "mse_ann, rmse_ann, r2_ann = calculate_metrics(y_test, y_pred_ann)\n",
    "\n",
    "# Creating a DataFrame to display actual and predicted prices\n",
    "results_ann = pd.DataFrame({'Actual Prices': y_test, 'Predicted Prices (ANN)': y_pred_ann})\n",
    "\n",
    "# Displaying the DataFrame and metrics\n",
    "print(\"Actual and Predicted Prices (ANN):\")\n",
    "print(results_ann.head())\n",
    "print(\"\\nPerformance Metrics (ANN):\")\n",
    "print(f'Mean Squared Error (ANN): {mse_ann}')\n",
    "print(f'Root Mean Squared Error (ANN): {rmse_ann}')\n",
    "print(f'R-squared (ANN): {r2_ann}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target variable\n",
    "target_variable = 'FRESHWORKS'\n",
    "\n",
    "# Get the target variable values\n",
    "y = data[target_variable].values.reshape(-1, 1)\n",
    "\n",
    "# Scale the target variable\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "y_scaled = scaler.fit_transform(y)\n",
    "\n",
    "# Define a function to create sequences\n",
    "def create_sequences(data, seq_length):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        seq = data[i:i+seq_length]\n",
    "        target = data[i+seq_length]\n",
    "        sequences.append(seq)\n",
    "        targets.append(target)\n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "# Define the sequence length\n",
    "sequence_length = 10\n",
    "\n",
    "# Create sequences for LSTM model\n",
    "X_seq, y_seq = create_sequences(y_scaled, sequence_length)\n",
    "\n",
    "# Split the data into train, validation, and test sets\n",
    "train_size = int(len(X_seq) * 0.7)\n",
    "val_size = int(len(X_seq) * 0.15)\n",
    "test_size = len(X_seq) - train_size - val_size\n",
    "\n",
    "X_train, y_train = X_seq[:train_size], y_seq[:train_size]\n",
    "X_val, y_val = X_seq[train_size:train_size+val_size], y_seq[train_size:train_size+val_size]\n",
    "X_test, y_test = X_seq[train_size+val_size:], y_seq[train_size+val_size:]\n",
    "\n",
    "# Define the LSTM model architecture\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model_lstm.add(Dense(1))\n",
    "model_lstm.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the LSTM model\n",
    "model_lstm.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), verbose=1)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_pred_lstm = model_lstm.predict(X_test)\n",
    "\n",
    "# Inverse transform the scaled predictions and actual values\n",
    "y_pred_lstm_inv = scaler.inverse_transform(y_pred_lstm)\n",
    "y_test_inv = scaler.inverse_transform(y_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse_lstm = np.sqrt(mean_squared_error(y_test_inv, y_pred_lstm_inv))\n",
    "\n",
    "# Plot actual vs. predicted prices\n",
    "test_dates = data.index[train_size+val_size : train_size+val_size+len(y_test_inv)]\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(test_dates, y_test_inv, label='Actual')\n",
    "plt.plot(test_dates, y_pred_lstm_inv, label='LSTM Prediction')\n",
    "plt.title(f'LSTM Prediction vs Actual (RMSE: {rmse_lstm:.2f})')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel(target_variable)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Calculate error percentage\n",
    "error_percentage = (rmse_lstm / np.mean(y_test_inv)) * 100\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse_lstm:.2f}')\n",
    "print(f'Error Percentage: {error_percentage:.2f}%')\n",
    "\n",
    "# Forecasting for the upcoming 7 days\n",
    "forecasted_values_scaled = []\n",
    "for i in range(7):\n",
    "    X_new = np.array([X_test[i]])\n",
    "    forecasted_value_scaled = model_lstm.predict(X_new)[0][0]\n",
    "    forecasted_values_scaled.append(forecasted_value_scaled)\n",
    "    X_test = np.concatenate((X_test, X_new), axis=0)\n",
    "\n",
    "forecasted_values = scaler.inverse_transform(np.array(forecasted_values_scaled).reshape(-1, 1))\n",
    "forecasted_dates = pd.date_range(data.index[-1], periods=7, freq='D')[1:]\n",
    "\n",
    "print(\"Forecasted stock prices for the upcoming 7 days:\")\n",
    "for date, price in zip(forecasted_dates, forecasted_values):\n",
    "    print(f\"{date.strftime('%Y-%m-%d')}: {price[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate evaluation metrics\n",
    "def calculate_metrics(y_test, y_pred):\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    return mse, rmse, mae\n",
    "\n",
    "# Splitting data into features (X) and target (y)\n",
    "X = data[['GOLD', 'PETROL', 'CURRENCY']]\n",
    "y = data['FRESHWORKS']\n",
    "\n",
    "# Splitting data into train, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=40)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Scaling features for ANN\n",
    "scaler_ann = StandardScaler()\n",
    "X_train_scaled_ann = scaler_ann.fit_transform(X_train)\n",
    "X_test_scaled_ann = scaler_ann.transform(X_test)\n",
    "X_val_scaled_ann = scaler_ann.transform(X_val)\n",
    "\n",
    "# Linear Regression\n",
    "model_lr = LinearRegression()\n",
    "model_lr.fit(X_train, y_train)\n",
    "y_pred_lr = model_lr.predict(X_test)\n",
    "mse_lr, rmse_lr, mae_lr = calculate_metrics(y_test, y_pred_lr)\n",
    "error_percentage_lr = (mae_lr / y_test.mean()) * 100\n",
    "\n",
    "# Random Forest\n",
    "model_rf = RandomForestRegressor(random_state=42)\n",
    "model_rf.fit(X_train, y_train)\n",
    "y_pred_rf = model_rf.predict(X_test)\n",
    "mse_rf, rmse_rf, mae_rf = calculate_metrics(y_test, y_pred_rf)\n",
    "error_percentage_rf = (mae_rf / y_test.mean()) * 100\n",
    "\n",
    "# k-Nearest Neighbors\n",
    "metrics_dict_knn = {'Feature': [], 'MSE': [], 'RMSE': [], 'MAE': []}\n",
    "for feature in X.columns:\n",
    "    current_feature = X_train[[feature]]\n",
    "    model_knn = KNeighborsRegressor(n_neighbors=5)\n",
    "    model_knn.fit(current_feature, y_train)\n",
    "    current_feature_test = X_test[[feature]]\n",
    "    y_pred_knn = model_knn.predict(current_feature_test)\n",
    "    mse_knn, rmse_knn, mae_knn = calculate_metrics(y_test, y_pred_knn)\n",
    "    metrics_dict_knn['Feature'].append(feature)\n",
    "    metrics_dict_knn['MSE'].append(mse_knn)\n",
    "    metrics_dict_knn['RMSE'].append(rmse_knn)\n",
    "    metrics_dict_knn['MAE'].append(mae_knn)\n",
    "\n",
    "metrics_df_knn = pd.DataFrame(metrics_dict_knn)\n",
    "error_percentage_knn = (metrics_df_knn['MAE'].mean() / y_test.mean()) * 100\n",
    "\n",
    "# Artificial Neural Network\n",
    "model_ann = Sequential()\n",
    "model_ann.add(Dense(32, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model_ann.add(Dense(16, activation='relu'))\n",
    "model_ann.add(Dense(1, activation='linear'))\n",
    "model_ann.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model_ann.fit(X_train_scaled_ann, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "y_pred_ann = model_ann.predict(X_test_scaled_ann).flatten()\n",
    "mse_ann, rmse_ann, mae_ann = calculate_metrics(y_test, y_pred_ann)\n",
    "error_percentage_ann = (mae_ann / y_test.mean()) * 100\n",
    "\n",
    "# LSTM\n",
    "target_variable = 'FRESHWORKS'\n",
    "y_lstm = data[target_variable].values.reshape(-1, 1)\n",
    "\n",
    "scaler_lstm = MinMaxScaler(feature_range=(0, 1))\n",
    "y_scaled_lstm = scaler_lstm.fit_transform(y_lstm)\n",
    "\n",
    "# Creating sequences for LSTM\n",
    "sequence_length_lstm = 10\n",
    "X_seq_lstm, y_seq_lstm = create_sequences(y_scaled_lstm, sequence_length_lstm)\n",
    "\n",
    "# Splitting sequences into train, validation, and test sets\n",
    "train_size_lstm = int(len(X_seq_lstm) * 0.7)\n",
    "val_size_lstm = int(len(X_seq_lstm) * 0.15)\n",
    "test_size_lstm = len(X_seq_lstm) - train_size_lstm - val_size_lstm\n",
    "\n",
    "X_train_lstm, y_train_lstm = X_seq_lstm[:train_size_lstm], y_seq_lstm[:train_size_lstm]\n",
    "X_val_lstm, y_val_lstm = X_seq_lstm[train_size_lstm:train_size_lstm+val_size_lstm], y_seq_lstm[train_size_lstm:train_size_lstm+val_size_lstm]\n",
    "X_test_lstm, y_test_lstm = X_seq_lstm[train_size_lstm+val_size_lstm:], y_seq_lstm[train_size_lstm+val_size_lstm:]\n",
    "\n",
    "# Creating and training LSTM model\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(50, input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])))\n",
    "model_lstm.add(Dense(1))\n",
    "model_lstm.compile(optimizer='adam', loss='mse')\n",
    "model_lstm.fit(X_train_lstm, y_train_lstm, epochs=50, batch_size=32, validation_data=(X_val_lstm, y_val_lstm), verbose=0)\n",
    "\n",
    "# Predicting on test set and inverse scaling\n",
    "y_pred_lstm = model_lstm.predict(X_test_lstm)\n",
    "y_pred_lstm_inv = scaler_lstm.inverse_transform(y_pred_lstm.reshape(-1, 1)).flatten()\n",
    "y_test_inv_lstm = scaler_lstm.inverse_transform(y_test_lstm.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Calculating evaluation metrics for LSTM\n",
    "rmse_lstm = np.sqrt(mean_squared_error(y_test_inv_lstm, y_pred_lstm_inv))\n",
    "error_percentage_lstm = (mean_absolute_error(y_test_inv_lstm, y_pred_lstm_inv) / np.mean(y_test_inv_lstm)) * 100\n",
    "\n",
    "# Displaying error percentage and RMSE for all models\n",
    "error_df = pd.DataFrame({\n",
    "    'Model': ['Linear Regression', 'Random Forest', 'k-Nearest Neighbors', 'Artificial Neural Network', 'LSTM'],\n",
    "    'RMSE': [rmse_lr, rmse_rf, metrics_df_knn['RMSE'].mean(), rmse_ann, rmse_lstm],\n",
    "    'Error Percentage': [error_percentage_lr, error_percentage_rf, error_percentage_knn, error_percentage_ann, error_percentage_lstm]\n",
    "})\n",
    "\n",
    "print(\"Error Percentage and RMSE for Different Models:\")\n",
    "print(error_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import finnhub\n",
    "import csv\n",
    "import datetime\n",
    "import yfinance as yf\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "\n",
    "finnhub_client = finnhub.Client(api_key=\"cohttk9r01qpcmnifpb0cohttk9r01qpcmnifpbg\")\n",
    "\n",
    "end_date = datetime.datetime.now().strftime('%Y-%m-%d')\n",
    "start_date = (datetime.datetime.now() - datetime.timedelta(days=2*365)).strftime('%Y-%m-%d')\n",
    "\n",
    "company_news = finnhub_client.company_news('FRSH', _from=start_date, to=end_date)\n",
    "\n",
    "aapl = yf.Ticker(\"FRSH\")\n",
    "aapl_history = aapl.history(start=start_date, end=end_date)\n",
    "close_prices = aapl_history['Close'].tolist()\n",
    "\n",
    "date_data = defaultdict(lambda: {'headlines': [], 'summaries': [], 'close_prices': []})\n",
    "for news_item, price in zip(company_news, close_prices):\n",
    "    date = datetime.datetime.utcfromtimestamp(news_item['datetime']).strftime('%Y-%m-%d')\n",
    "    date_data[date]['headlines'].append(news_item['headline'])\n",
    "    date_data[date]['summaries'].append(news_item['summary'])\n",
    "    date_data[date]['close_prices'].append(price)\n",
    "\n",
    "for date, data in date_data.items():\n",
    "    avg_close_price = sum(data['close_prices']) / len(data['close_prices'])\n",
    "    date_data[date]['close_price'] = avg_close_price\n",
    "\n",
    "csv_file = \"company_news.csv\"\n",
    "\n",
    "with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['date', 'headline', 'summary', 'close_price'])\n",
    "    for date, data in date_data.items():\n",
    "        writer.writerow([date, \", \".join(data['headlines']), \", \".join(data['summaries']), data['close_price']])\n",
    "\n",
    "print(\"Data saved to\", csv_file)\n",
    "\n",
    "# print(finnhub_client.stock_symbols('US'))\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "df['headline'].fillna('', inplace=True)\n",
    "df['summary'].fillna('', inplace=True)\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "df['Headline_Sentiment'] = df['headline'].apply(lambda x: sid.polarity_scores(str(x))['compound'])\n",
    "df['Content_Sentiment'] = df['summary'].apply(lambda x: sid.polarity_scores(str(x))['compound'])\n",
    "\n",
    "df.to_csv('sentiment_with_scores.csv', index=False)\n",
    "\n",
    "X = df[['Headline_Sentiment', 'Content_Sentiment']]\n",
    "y = df['close_price']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "test_preds = model.predict(X_test)\n",
    "\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "test_preds = pd.Series(test_preds, name='Predicted')\n",
    "\n",
    "mse_test = mean_squared_error(y_test, test_preds)\n",
    "rmse_test = sqrt(mse_test)\n",
    "mae_test = mean_absolute_error(y_test, test_preds)\n",
    "\n",
    "range_close = y.max() - y.min()\n",
    "mse_percentage = (mse_test / range_close) * 100\n",
    "rmse_percentage = (rmse_test / range_close) * 100\n",
    "mae_percentage = (mae_test / range_close) * 100\n",
    "\n",
    "table = [['Metric', 'Error', 'Error Percentage'],\n",
    "         ['MSE', mse_test, mse_percentage],\n",
    "         ['RMSE', rmse_test, rmse_percentage],\n",
    "         ['MAE', mae_test, mae_percentage]]\n",
    "\n",
    "print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_test.index, y_test, label='Actual Close Prices', color='blue')\n",
    "plt.plot(y_test.index, test_preds, label='Predicted Close Prices', color='orange')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Close Prices')\n",
    "plt.title('Actual vs. Predicted Close Prices')\n",
    "plt.legend()\n",
    "\n",
    "plt.xticks(y_test.index, df.loc[y_test.index, 'date'], rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
