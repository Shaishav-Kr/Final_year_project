{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from tabulate import tabulate\n",
    "import nltk\n",
    "from math import sqrt\n",
    "\n",
    "# Function to download financial data\n",
    "def download_data(ticker, start_date, end_date):\n",
    "    try:\n",
    "        df = yf.download(ticker, start=start_date, end=end_date)\n",
    "        df = df['Close'].rename(ticker)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading data for {ticker}: {e}\")\n",
    "        return pd.Series(name=ticker)\n",
    "\n",
    "# Setting start and end dates for data\n",
    "end_date = datetime.datetime.now().strftime('%Y-%m-%d')\n",
    "start_date = (datetime.datetime.now() - datetime.timedelta(days=20*365)).strftime('%Y-%m-%d')\n",
    "\n",
    "# List of tickers to download data for\n",
    "tickers = ['FRSH', 'NEM', 'XOM', 'INR=X']\n",
    "\n",
    "# Downloading data for each ticker and merging\n",
    "dataframes = [download_data(ticker, start_date, end_date) for ticker in tickers]\n",
    "merged_data = pd.concat(dataframes, axis=1).dropna()\n",
    "merged_data.columns = ['FRESHWORKS', 'GOLD', 'PETROL', 'CURRENCY']\n",
    "\n",
    "# Saving merged data to a CSV file\n",
    "merged_data.to_csv('merged_data.csv')\n",
    "\n",
    "# Checking for NaN values\n",
    "if merged_data.isna().any().any():\n",
    "    print(\"Warning: NaN values present in the merged data.\")\n",
    "else:\n",
    "    print(\"Data downloaded and merged successfully.\")\n",
    "\n",
    "# Loading merged data from CSV\n",
    "data = pd.read_csv('merged_data.csv')\n",
    "\n",
    "# Converting 'Date' column to datetime format\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "# Setting 'Date' column as index\n",
    "data.set_index('Date', inplace=True)\n",
    "\n",
    "# Dropping rows with NaN values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Displaying data types of columns\n",
    "print(data.dtypes)\n",
    "\n",
    "# Displaying data\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target variable\n",
    "target_variable = 'FRESHWORKS'\n",
    "\n",
    "# Get the target variable values\n",
    "y = data[target_variable].values.reshape(-1, 1)\n",
    "\n",
    "# Scale the target variable\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "y_scaled = scaler.fit_transform(y)\n",
    "\n",
    "# Define a function to create sequences\n",
    "def create_sequences(data, seq_length):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        seq = data[i:i+seq_length]\n",
    "        target = data[i+seq_length]\n",
    "        sequences.append(seq)\n",
    "        targets.append(target)\n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "# Define the sequence length\n",
    "sequence_length = 10\n",
    "\n",
    "# Create sequences for LSTM model\n",
    "X_seq, y_seq = create_sequences(y_scaled, sequence_length)\n",
    "\n",
    "# Split the data into train, validation, and test sets\n",
    "train_size = int(len(X_seq) * 0.7)\n",
    "val_size = int(len(X_seq) * 0.15)\n",
    "test_size = len(X_seq) - train_size - val_size\n",
    "\n",
    "X_train, y_train = X_seq[:train_size], y_seq[:train_size]\n",
    "X_val, y_val = X_seq[train_size:train_size+val_size], y_seq[train_size:train_size+val_size]\n",
    "X_test, y_test = X_seq[train_size+val_size:], y_seq[train_size+val_size:]\n",
    "\n",
    "# Define the LSTM model architecture\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model_lstm.add(Dense(1))\n",
    "model_lstm.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the LSTM model\n",
    "model_lstm.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), verbose=1)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_pred_lstm = model_lstm.predict(X_test)\n",
    "\n",
    "# Inverse transform the scaled predictions and actual values\n",
    "y_pred_lstm_inv = scaler.inverse_transform(y_pred_lstm)\n",
    "y_test_inv = scaler.inverse_transform(y_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse_lstm = np.sqrt(mean_squared_error(y_test_inv, y_pred_lstm_inv))\n",
    "\n",
    "# Plot actual vs. predicted prices\n",
    "test_dates = data.index[train_size+val_size : train_size+val_size+len(y_test_inv)]\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(test_dates, y_test_inv, label='Actual')\n",
    "plt.plot(test_dates, y_pred_lstm_inv, label='LSTM Prediction')\n",
    "plt.title(f'LSTM Prediction vs Actual (RMSE: {rmse_lstm:.2f})')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel(target_variable)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Calculate error percentage\n",
    "error_percentage = (rmse_lstm / np.mean(y_test_inv)) * 100\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse_lstm:.2f}')\n",
    "print(f'Error Percentage: {error_percentage:.2f}%')\n",
    "\n",
    "# Forecasting for the upcoming 7 days\n",
    "forecasted_values_scaled = []\n",
    "for i in range(7):\n",
    "    X_new = np.array([X_test[i]])\n",
    "    forecasted_value_scaled = model_lstm.predict(X_new)[0][0]\n",
    "    forecasted_values_scaled.append(forecasted_value_scaled)\n",
    "    X_test = np.concatenate((X_test, X_new), axis=0)\n",
    "\n",
    "forecasted_values = scaler.inverse_transform(np.array(forecasted_values_scaled).reshape(-1, 1))\n",
    "forecasted_dates = pd.date_range(data.index[-1], periods=7, freq='D')[1:]\n",
    "\n",
    "print(\"Forecasted stock prices for the upcoming 7 days:\")\n",
    "for date, price in zip(forecasted_dates, forecasted_values):\n",
    "    print(f\"{date.strftime('%Y-%m-%d')}: {price[0]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
